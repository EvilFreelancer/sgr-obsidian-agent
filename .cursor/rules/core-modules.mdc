---
description: Rules for core modules of SGR Obsidian Agent
globs: src/core/**/*.ts, src/settings/**/*.ts
alwaysApply: true
---

# Rules for Core Modules

## LLMClient Module

### Responsibilities
- Communication with OpenAI-compatible API
- Model fetching from `/models` endpoint
- Chat completion requests
- Streaming support (SSE)
- Error handling for API errors

### Implementation Rules
- Use `fetch` API for HTTP requests
- Support both streaming and non-streaming modes
- Handle authentication with Bearer token
- Parse SSE streams correctly
- Return structured error types

### Interface
```typescript
class LLMClient {
  private baseUrl: string;
  private apiKey: string;
  private proxy?: string;
  
  constructor(baseUrl: string, apiKey: string, proxy?: string);
  async fetchModels(): Promise<Model[]>;
  async sendMessage(
    model: string,
    messages: ChatMessage[],
    options?: ChatOptions
  ): Promise<AsyncIterable<string>>;
  private async *parseSSEStream(body: ReadableStream<Uint8Array>): AsyncIterable<string>;
}
```

### Implementation Details
- Base URL is normalized (trailing slash removed)
- Proxy URL is used for both `/models` and `/chat/completions` endpoints if provided
- SSE parsing handles partial chunks and buffers incomplete lines
- Extracts content from `parsed.choices[0].delta.content`
- Stops on `[DONE]` marker

### Error Handling
- Network errors → `NetworkError`
- API errors (4xx, 5xx) → `LLMAPIError` with status code
- Invalid model → `InvalidModelError`
- Rate limits → `RateLimitError`

## ChatManager Module

### Responsibilities
- Manage chat session state via `ChatSession` interface
- Handle three modes: Agent, Ask, Plan (from `CHAT_MODES` constant)
- Manage file context from @ mentions (reads files from Obsidian vault)
- Coordinate between UI and LLM client
- Build system prompts based on mode (from `SYSTEM_PROMPTS` constant)

### Implementation Rules
- Store messages in memory during session (`ChatSession.messages`)
- System prompt added as first message with role 'system' on `startSession()`
- File context added to user message content (not system message)
- Format: `[File: path]\ncontent\n[/File]` for each file, then user question
- Handle streaming responses via `appendAssistantMessage()` for incremental updates
- Session state includes: messages, mode, model, fileContexts

### ChatSession Interface
```typescript
interface ChatSession {
  messages: ChatMessage[];
  mode: ChatMode;
  model: string;
  fileContexts: FileContext[];
}
```

### Methods
- `startSession(mode: ChatMode, model: string)`: Initialize new session with system prompt
- `addFileContext(filePath: string)`: Read file from vault and add to session
- `removeFileContext(filePath: string)`: Remove file from context
- `sendMessage(userMessage: string)`: Send message with file contexts, returns stream
- `appendAssistantMessage(content: string)`: Append chunk to last assistant message or create new
- `getCurrentSession()`: Get current session or null
- `clearSession()`: Clear current session
- `saveSession(title: string)`: Save session to MessageRepository
- `loadSession(filePath: string)`: Load session from MessageRepository
- `updateClient(baseUrl, apiKey, proxy?)`: Update LLM client configuration

### Modes
- **Agent**: Autonomous agent with tools
- **Ask**: Simple Q&A assistant
- **Plan**: Planning assistant with step-by-step execution

### System Prompts
- Stored in `constants.ts` as `SYSTEM_PROMPTS` object
- Agent: "You are an autonomous AI agent. You can use tools to accomplish tasks. Think step by step and decide which actions to take."
- Ask: "You are a helpful assistant. Answer questions directly and concisely."
- Plan: "You are a planning assistant. Break down tasks into steps and execute them systematically."

## MessageRepository Module

### Responsibilities
- Save chat history to markdown files
- Load chat history from files
- Manage chat metadata (title, dates, model, mode)
- List all saved chats
- Delete chat files

### Implementation Rules
- Save to `chatHistoryFolder` setting
- Use frontmatter for metadata
- Markdown format for messages
- Handle file operations with Obsidian API
- Validate file paths

### File Format
```yaml
---
title: "Chat Title"
createdAt: "2024-01-01T12:00:00Z"
lastAccessedAt: "2024-01-01T12:00:00Z"
model: "gpt-4"
mode: "agent"
---

## User
Message text

## Assistant
Response text
```

### Implementation Details
- Frontmatter parsing uses regex: `/^---\n([\s\S]*?)\n---\n/`
- Message parsing uses regex: `/^## (User|Assistant)\n/gm`
- System messages are excluded from saved chats
- Filenames sanitized: invalid chars replaced with `-`, max 100 chars
- Folder created automatically if not exists via `ensureFolderExists()`
- Chats sorted by `lastAccessedAt` descending (newest first)

## Settings Module

### Responsibilities
- Define settings interface
- Provide default values
- Validate settings
- Handle settings persistence

### Implementation Rules
- Use `AgentSettings` interface
- Validate required fields (baseUrl, apiKey)
- Validate ranges (temperature: 0-2)
- Provide sensible defaults
- Handle missing settings gracefully

### Settings Interface
```typescript
interface AgentSettings {
  baseUrl: string;
  apiKey: string;
  proxy?: string;
  defaultModel: string;
  temperature: number;
  maxTokens: number;
  chatHistoryFolder: string;
}
```

## General Rules for All Core Modules

1. **Type safety**: Use TypeScript types everywhere
2. **Error handling**: Use specific error types, not generic Error
3. **Async/await**: Use async/await for all async operations
4. **Documentation**: Document public methods with JSDoc comments (in English)
5. **Immutability**: Don't mutate input parameters
6. **Single responsibility**: Each module has one clear purpose

## Dependencies

### LLMClient
- No dependencies on other core modules
- Can depend on `types/` and `utils/`

### ChatManager
- Depends on `LLMClient`
- Depends on `MessageRepository` (optional, for auto-save)
- Can depend on `types/` and `utils/`

### MessageRepository
- Depends on Obsidian API (`app.vault`)
- Can depend on `types/` and `utils/`

### Settings
- No dependencies on other core modules
- Can depend on `types/`

## References

@SPECIFICATION.md
@architecture.mdc
@code-style.mdc
